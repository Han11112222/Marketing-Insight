# app.py â€” Gas Sales Analytics (Landing + Aggregations + Industrial Focus)
# - íƒ­3: [ì‚°ì—…ìš© ì§‘ì¤‘ë¶„ì„] ì—…ì¢…Ã—ê¸°ê°„ íˆíŠ¸ë§µ â†’ ì…€ í´ë¦­: ê³ ê° Top-N / YoY / ë‹¤ìš´ë¡œë“œ

import os
import numpy as np
import pandas as pd
import streamlit as st
import plotly.graph_objects as go
from streamlit_plotly_events import plotly_events
import time

st.set_page_config(page_title="ë„ì‹œê°€ìŠ¤ íŒë§¤ëŸ‰ ë¶„ì„", layout="wide")
FONT = "Noto Sans KR, Pretendard, Arial, sans-serif"

# ì¶”ê°€ ìš©ë„(ëŒ€ì‹œë³´ë“œ ì²« í™”ë©´ì— ìˆìœ¼ë©´ í•¨ê»˜ ìŠ¤íƒìœ¼ë¡œ í‘œì‹œ)
CAND_EXTRA = [
    "ìˆ˜ì†¡ìš©", "ì—…ë¬´ìš©", "ì—°ë£Œì „ì§€ìš©", "ì—´ì „ìš©ì„¤ë¹„ìš©",
    "ì—´ë³‘í•©ìš©", "ì—´ë³‘í•©ìš©1", "ì—´ë³‘í•©ìš©2",
    "ì¼ë°˜ìš©", "ì¼ë°˜ìš©(1)", "ì¼ë°˜ìš©(2)"
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê³µí†µ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def to_num(x):
    """ìˆ«ì ë³€í™˜ í•¨ìˆ˜"""
    if isinstance(x, str):
        x = x.replace(",", "")
    return pd.to_numeric(x, errors="coerce")

def as_period_key(dt: pd.Series, gran: str) -> pd.Series:
    """ë‚ ì§œ ë°ì´í„°ë¥¼ ì›”/ë¶„ê¸°/ë°˜ê¸°/ì—°ê°„ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
    d = pd.to_datetime(dt)
    if gran == "ì›”":
        return d.dt.to_period("M").astype(str)          # e.g., '2025-09'
    elif gran == "ë¶„ê¸°":
        return d.dt.to_period("Q").astype(str)          # e.g., '2025Q3'
    elif gran == "ë°˜ê¸°":
        y = d.dt.year.astype(str)
        h = np.where(d.dt.month <= 6, "H1", "H2")
        return (y + h)                                  # e.g., '2025H1'
    else:
        return d.dt.year.astype(str)                    # e.g., '2025'

def yoy_compare(df, key_cols, value_col, period_col, gran: str):
    """YoY ë¹„êµí‘œ ìƒì„± í•¨ìˆ˜"""
    lag_map = {"ì›”": 12, "ë¶„ê¸°": 4, "ë°˜ê¸°": 2, "ì—°ê°„": 1}
    lag = lag_map.get(gran, 12)
    p = df[period_col].astype(str)

    if gran in ["ì›”", "ë¶„ê¸°"]:
        prev = (pd.PeriodIndex(p) - lag).astype(str)
    elif gran == "ë°˜ê¸°":
        y = p.str[:4].astype(int)
        h = p.str[-2:].map({"H1": 1, "H2": 2}).astype(int)
        idx = (y - y.min()) * 2 + (h - 1)
        prev_idx = idx - 2
        base = y.min()
        prev = ((prev_idx // 2) + base).astype(str) + np.where((prev_idx % 2) == 0, "H1", "H2")
    else:
        prev = (p.astype(int) - 1).astype(str)

    cur = df.copy()
    cur["_prev"] = prev
    a = cur.groupby(key_cols + [period_col], as_index=False)[value_col].sum()
    b = (
        cur.rename(columns={period_col: "_prev"})
        .groupby(key_cols + ["_prev"], as_index=False)[value_col]
        .sum()
        .rename(columns={value_col: "ì „ë…„ë™ê¸°"})
    )
    out = pd.merge(a, b, how="left", left_on=key_cols + [period_col], right_on=key_cols + ["_prev"])
    out.drop(columns=["_prev"], inplace=True, errors="ignore")
    out["ì¦ê°"] = out[value_col] - out["ì „ë…„ë™ê¸°"]
    out["YoY(%)"] = np.where(out["ì „ë…„ë™ê¸°"].abs() > 1e-9, out["ì¦ê°"] / out["ì „ë…„ë™ê¸°"] * 100, np.nan)
    return out

@st.cache_data(show_spinner=False)
def read_parquet_any(path_or_buf):
    """parquet íŒŒì¼ ì½ëŠ” í•¨ìˆ˜"""
    try:
        return pd.read_parquet(path_or_buf)
    except Exception as e:
        st.error(f"Error reading parquet file: {e}")
        return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë°ì´í„° ì…ë ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.header("â‘  ë°ì´í„° ì—…ë¡œë“œ")
st.sidebar.caption("A: ì›”ë³„ ì´ê´„(ì£¼íƒ/ì‚°ì—… í•©ì‚°), B: ì‚°ì—…ìš© ìƒì„¸(ê³ ê°/ì—…ì¢…)")

up_overall = st.sidebar.file_uploader("A) ì›”ë³„ ì´ê´„ (Parquet)", type=["parquet"])
if up_overall:
    overall_raw = read_parquet_any(up_overall)
    used_overall = up_overall.name
else:
    st.info("A(ì›”ë³„ ì´ê´„)ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    st.stop()

colsA = overall_raw.columns.astype(str).tolist()
st.sidebar.header("â‘¡ A(ì›”ë³„ ì´ê´„) ì»¬ëŸ¼ ë§¤í•‘")
def _pickA(keys, default_idx=0):
    for k in keys:
        for c in colsA:
            if k in c:
                return c
    return colsA[default_idx]

c_date   = st.sidebar.selectbox("ë‚ ì§œ", colsA, index=colsA.index(_pickA(["ë‚ ì§œ","Date","ì›”"])) if _pickA(["ë‚ ì§œ","Date","ì›”"]) in colsA else 0)
c_cook   = st.sidebar.selectbox("ì·¨ì‚¬ìš©", colsA, index=colsA.index(_pickA(["ì·¨ì‚¬ìš©"])) if _pickA(["ì·¨ì‚¬ìš©"]) in colsA else 1)

overall = overall_raw.copy()
overall["ë‚ ì§œ"] = pd.to_datetime(overall[c_date], errors="coerce")
overall["ì·¨ì‚¬ìš©"] = overall[c_cook].apply(to_num)

up_indetail = st.sidebar.file_uploader("B) ì‚°ì—…ìš© ìƒì„¸ (Parquet)", type=["parquet"], accept_multiple_files=True)
used_inds = []
if up_indetail:
    frames = []
    for f in up_indetail:
        used_inds.append(f.name)
        df = read_parquet_any(f)
        if df is not None:
            frames.append(df)
    indetail_raw = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()
else:
    st.info("B(ì‚°ì—…ìš© ìƒì„¸)ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë²”ìœ„ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("ğŸ“Š ë„ì‹œê°€ìŠ¤ íŒë§¤ëŸ‰ ë¶„ì„")
date_min = min(overall["ë‚ ì§œ"].min(), indetail_raw["ë‚ ì§œ"].min()) if len(indetail_raw) > 0 else overall["ë‚ ì§œ"].min()
date_max = max(overall["ë‚ ì§œ"].max(), indetail_raw["ë‚ ì§œ"].max()) if len(indetail_raw) > 0 else overall["ë‚ ì§œ"].max()
d1, d2 = st.sidebar.date_input("ê¸°ê°„", [pd.to_datetime(date_min), pd.to_datetime(date_max)])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ íƒ­ êµ¬ì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
tab0, tab1, tab2 = st.tabs(["ğŸ  ëŒ€ì‹œë³´ë“œ", "ğŸ“š ì§‘ê³„", "ğŸ­ ì‚°ì—…ìš© ì§‘ì¤‘ë¶„ì„"])

# íƒ­0: ëœë”©(ì—°ë„Ã—ìš©ë„ ìŠ¤íƒ)
with tab0:
    st.subheader("ì—°ë„ë³„ ìš©ë„ ëˆ„ì  ìŠ¤íƒ")
    landing = overall[(overall["ë‚ ì§œ"] >= pd.to_datetime(d1)) & (overall["ë‚ ì§œ"] <= pd.to_datetime(d2))].copy()
    landing["ì—°ë„"] = landing["ë‚ ì§œ"].dt.year
    usage_cols = ["ì·¨ì‚¬ìš©"]  # í•„ìš”ì— ë”°ë¼ ì¶”ê°€ ìš©ë„ë“¤ ì¶”ê°€
    annual = landing.groupby("ì—°ë„", as_index=False)[usage_cols].sum().sort_values("ì—°ë„")
    fig0 = go.Figure()
    for col in usage_cols:
        fig0.add_trace(go.Bar(x=annual["ì—°ë„"], y=annual[col], name=col))
    fig0.update_layout(barmode="stack", template="simple_white", height=420)
    st.plotly_chart(fig0, use_container_width=True)

# íƒ­1: ì§‘ê³„
with tab1:
    st.subheader("ì§‘ê³„ â€” ì›”/ë¶„ê¸°/ë°˜ê¸°/ì—°ê°„")
    gran = st.radio("ì§‘ê³„ ë‹¨ìœ„", ["ì›”", "ë¶„ê¸°", "ë°˜ê¸°", "ì—°ê°„"], horizontal=True, key="granularity")
    A = overall[(overall["ë‚ ì§œ"] >= pd.to_datetime(d1)) & (overall["ë‚ ì§œ"] <= pd.to_datetime(d2))].copy()
    A["Period"] = as_period_key(A["ë‚ ì§œ"], gran)
    sum_tbl = A.groupby("Period", as_index=False)[usage_cols].sum().sort_values("Period")
    st.dataframe(sum_tbl)

# íƒ­2: ì‚°ì—…ìš© ì§‘ì¤‘ë¶„ì„
with tab2:
    st.subheader("ì‚°ì—…ìš© ì§‘ì¤‘ë¶„ì„ â€” ì—…ì¢…Ã—ê¸°ê°„ íˆíŠ¸ë§µ")
    if len(indetail_raw) == 0:
        st.info("ì‚°ì—…ìš© ìƒì„¸ íŒŒì¼(B)ì´ ì—†ì–´ íˆíŠ¸ë§µì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    gran_focus = st.radio("ê¸°ê°„ ë‹¨ìœ„", ["ì›”", "ë¶„ê¸°", "ë°˜ê¸°", "ì—°ê°„"], horizontal=True, key="gran_focus")
    B = indetail_raw[(indetail_raw["ë‚ ì§œ"] >= pd.to_datetime(d1)) & (indetail_raw["ë‚ ì§œ"] <= pd.to_datetime(d2))].copy()

    B["Period"] = as_period_key(B["ë‚ ì§œ"], gran_focus)
    pivot = B.pivot_table(index="ì—…ì¢…", columns="Period", values="ì‚¬ìš©ëŸ‰", aggfunc="sum").fillna(0)
    Z = pivot.values
    X = pivot.columns.tolist()
    Y = pivot.index.tolist()
    heat = go.Figure(data=go.Heatmap(z=Z, x=X, y=Y, colorscale="Blues", colorbar=dict(title="ì‚¬ìš©ëŸ‰")))
    st.plotly_chart(heat)

# ì‚¬ìš©ëœ íŒŒì¼ í™•ì¸
with st.expander("ğŸ” ë¶„ì„ì— ì‚¬ìš©ëœ ì›ì²œ íŒŒì¼"):
    st.write(f"A(ì›”ë³„ ì´ê´„): **{used_overall}**")
    st.write(f"B(ì‚°ì—…ìš© ìƒì„¸): {', '.join(used_inds)}")
